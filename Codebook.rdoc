= Code Book for the wearable computing project (run_analysis.R)
This is the code book for the raw to tidy data transformation. This process is carried out by the run_analysis.R script 
that extracts raw data from different files in UCI HAR Dataset directory were the wearable computing project data is located

== Meta-data (Raw data)

=== General Description (Extracted from the documentation of the data set).

The data was extracted from the url: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
and it has multiple variable values corresponging to the "Human Activity Recognition Using Smartphones Dataset" project.
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person 
performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone
(Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, they captured 3-axial linear acceleration
and 3-axial angular velocity at a constant rate of 50Hz. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers 
was selected for generating the training data and 30% the test data.

=== Data set files

* features_info.txt 
Shows information about the variables used on the feature vector.

* features.txt 
List of all features.

* activity_labels.txt 
Links the class labels with their activity name.

* train/X_train.txt
Training set.

* train/y_train.txt 
Training labels.

* test/X_test.txt 
Test set.

* test/y_test.txt
Test labels.

The following files are available for the train and test data. Their descriptions are equivalent.

* train/subject_train.txt 
Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30. 

* train/Inertial Signals/total_acc_x_train.txt
The acceleration signal from the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element vector. The same description applies for the 'total_acc_x_train.txt' and 'total_acc_z_train.txt' files for the Y and Z axis. 

* train/Inertial Signals/body_acc_x_train.txt 
The body acceleration signal obtained by subtracting the gravity from the total acceleration. 

* train/Inertial Signals/body_gyro_x_train.txt 
The angular velocity vector measured by the gyroscope for each window sample. The units are radians/second. 

=== Features
The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 
Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 
Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

* tBodyAcc-XYZ
* tGravityAcc-XYZ
* tBodyAccJerk-XYZ
* tBodyGyro-XYZ
* tBodyGyroJerk-XYZ
* tBodyAccMag
* tGravityAccMag
* tBodyAccJerkMag
* tBodyGyroMag
* tBodyGyroJerkMag
* fBodyAcc-XYZ
* fBodyAccJerk-XYZ
* fBodyGyro-XYZ
* fBodyAccMag
* fBodyAccJerkMag
* fBodyGyroMag
* fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 

* mean(): Mean value
* std(): Standard deviation
* mad(): Median absolute deviation 
* max(): Largest value in array
* min(): Smallest value in array
* sma(): Signal magnitude area
* energy(): Energy measure. Sum of the squares divided by the number of values. 
* iqr(): Interquartile range 
* entropy(): Signal entropy
* arCoeff(): Autorregresion coefficients with Burg order equal to 4
* correlation(): correlation coefficient between two signals
* maxInds(): index of the frequency component with largest magnitude
* meanFreq(): Weighted average of the frequency components to obtain a mean frequency
* skewness(): skewness of the frequency domain signal 
* kurtosis(): kurtosis of the frequency domain signal 
* bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.
* angle(): Angle between to vectors.

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:

* gravityMean
* tBodyAccMean
* tBodyAccJerkMean
* tBodyGyroMean
* tBodyGyroJerkMean

=== License and acknowledgements

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012.

This dataset is distributed AS-IS and no responsibility implied or explicit can be addressed to the authors or their institutions for its use or misuse. Any commercial use is prohibited.
Jorge L. Reyes-Ortiz, Alessandro Ghio, Luca Oneto, Davide Anguita. November 2012.

=== Observations (Raw data)
* Even the subject number goes up to 30 there's only 21 subjects.
* The quantity of observations per each activity is not the same for all subjects. In other words if there are four observations for any subject in "WALKING" activity there are more o less than four observations in other activities.
* The files with the name y_train and y_test suits the activities performed for each subject.
* Even the angle variables were calculated with the mean of other variables (gravityMean, tBodyAccMean, tBodyAccJerkMean, tBodyAccJerkMean, tBodyGyroMean, tBodyGyroMean, tBodyGyroJerkMean) they're not used to concieve the tidy data set

== Meta-data (Tidy data)
* Everthing about the output 
== How the run_analisys script works?
=== Parameters

This function has only one parameter and it's the path where the UCI HAR Dataset directory is located. If the parameter is ommited
the "getwd" function is used to get the default working directory configured in R.

=== Local variables

* df_actdstr 
Data frame of activities dataset in the train directory (y_train.txt)
* df_subdstr
Data frame of subjects dataset in the train directory (subject_train.txt)
* df_valdstr
Data frame of values dataset in the train directory (x_train.txt)
* df_actdste: 
Data frame of activities dataset in the test directory (y_test.txt)
* df_subdste
Data frame of subjects dataset in the test directory (subject_test.txt)
* df_valdste
Data frame of values dataset in the test directory (x_test	.txt)

=== Process
* Invoking Libraries
  The code starts with a notification, then it loads the libraries
    message("Executing! please wait...")
    suppressMessages(library(dplyr))
    suppressMessages(library(plyr))
    suppressMessages(library(base))
    
* Step 1. Verifies the files existence
It uses the...
  if(!file.exists(paste(c(rds_path,"/UCI HAR Dataset/test/subject_test.txt"),collapse=''))){
    message("subject_test.txt is not available! Please check the directory path.")
    return(FALSE)
  }
  
* Step 2. Check the number of rows for y_train(Activites), subject_train and x_train)
It uses the...
  df_actdstr <- read.table(paste(c(rds_path,"/UCI HAR Dataset/train/y_train.txt"),collapse=''))
  df_subdstr <- read.table(paste(c(rds_path,"/UCI HAR Dataset/train/subject_train.txt"),collapse=''))  
  df_valdstr <- read.table(paste(c(rds_path,"/UCI HAR Dataset/train/x_train.txt"),collapse=''))
  
Then it...
  if(nrow(df_actdstr) != nrow(df_subdstr) | nrow(df_valdstr) != nrow(df_subdstr)){
    message("The files in train directory don't have the same number of observations!")
    return(FALSE)
  }
  
* Step 3. Check the number of rows for y_test(Activites), subject_test and x_test)
It uses the...
  df_actdste <- read.table(paste(c(rds_path,"/UCI HAR Dataset/test/y_test.txt"),collapse=''))
  df_subdste <- read.table(paste(c(rds_path,"/UCI HAR Dataset/test/subject_test.txt"),collapse=''))
  df_valdste <- read.table(paste(c(rds_path,"/UCI HAR Dataset/test/x_test.txt"),collapse=''))
  
Then it...
  if(nrow(df_actdste) != nrow(df_subdste) | nrow(df_valdste) != nrow(df_subdste)){
    message("The files in test directory don't have the same number of observations!")
    return(FALSE)
  }
  
* Step 4. Binds (Merges) the training and the test sets to create one data set
It uses the...
  df_acticom <-rbind(df_valdstr,df_valdste)
  
* Step 5. Set the Variable(column) names
It uses the...
  df_varname <- read.table(paste(c(rds_path,"/UCI HAR Dataset/features.txt"),collapse=''))
  df_varname <- df_varname$V2
  df_varname <- gsub("[[:punct:]]", "", df_varname)
  colnames(df_acticom) <- df_varname
  
* Step 6. Extracts only the measurements on the mean and standard deviation for each measurement
It uses the...
 
  df_data <- df_acticom[,-(461:502)]
  df_data <- df_data[,-(513:519)]
  df_data <- tbl_df(df_data)
  df_data <- cbind(select(df_data,contains("mean",ignore.case = TRUE)),select(df_data,contains("std",ignore.case = TRUE)))

* Step 7. Changes de activities code number by their description
It uses the...

  df_actlb <- read.table(paste(c(rds_path,"/UCI HAR Dataset/activity_labels.txt"),collapse=''))
  df_joacttr <- suppressMessages(join(df_actlb,df_actdstr))
  df_joactte <- suppressMessages(join(df_actlb,df_actdste))
  df_acticom <- rbind(df_joacttr,df_joactte)
  colnames(df_acticom) <- c("Activity_code","Activity_desc")
  
* Step 8. Merges the activites with the data set
It uses the...

  df_data <- cbind(select(df_acticom,Activity_desc),df_data)
  
* Step 9. Extract the subjects and sets the Variable (column) names
It uses the...

  df_josucom <- rbind(df_subdstr,df_subdste)
  colnames(df_josucom) <- c("Subject_num")

* Step 10. Merge the subjects with the data set
It uses the...

  df_data <- cbind(select(df_josucom,Subject_num),df_data
  
* Step 11. Detach package plyr to use summarize properly
It uses the...
  detach("package:plyr", unload=TRUE)
  suppressMessages(library(dplyr))

* Step 12. Create the file with the tidy data
It uses the...

  gr_subacmen <- df_data %>%
  group_by(Activity_desc,Subject_num) %>%
  summarise_each(funs(mean))
  message(paste(c("Creating secondary tidy data set in ",rds_path,"/tidymeanset.txt"),collapse=''))
  write.table(gr_subacmen, file = paste(c(rds_path,"/tidymeanset.txt"),collapse=''),row.names = FALSE)
  message("Process succesfully finished!")
  return(df_data)
  
== Authors
Created by Ronald Rodríguez (ronaldraxon)
